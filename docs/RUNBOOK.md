# NetVis Recon Toolkit Runbook

This repository contains two integrated layers:

1. **NetVis GUI (Graph + Dashboard)**: interactive network discovery, traffic capture, persistence, and an "intel story" view.
2. **NetVis Recon Toolkit (Modules 1–7 + Workbench Multi-Chain)**: rubric-aligned reconnaissance techniques with structured logs, IDS exercises, and an aggregated casefile/story pipeline.

This runbook is written to help you:
- understand what the project can do (capability sheet),
- run everything from the UI (no copy/paste required),
- reproduce the same runs via CLI/API when needed (for your Appendix/TA verification),
- explain the **multi-chain discovery** (what runs, in what order, and how the evidence is fused).

## Safety / Guardrails (Important)

- **Private targets only**: all coursework runners and the multi-chain pipeline enforce `toolkit.utils.ensure_private_target()` for IPs/CIDRs. Public targets are refused.
- **Spoofing techniques are gated**: Module 3 idle scan + decoy mixing require explicit acknowledgement (`lab_ok` in UI or `--lab-ok` in CLI).
- **Coursework API endpoints are local-only by default**: if `NETVIS_API_KEY` is unset, `/api/coursework/*` refuses non-local requests.

## Quick Start (UI)

### 1) Backend (Python/Flask)

Run the backend on port `5001` (root required for most packet techniques):

```bash
cd <repo-root>
sudo venv/bin/python app.py --host 127.0.0.1 --port 5001
```

Optional demo mode (no root required; synthetic data):

```bash
cd <repo-root>
venv/bin/python app.py --demo --host 127.0.0.1 --port 5001
```

### 2) Frontend (React/Vite)

```bash
cd <repo-root>
npm run dev
```

Open the UI at:
- `http://localhost:3000`

## Where Data Goes (Artifacts + Persistence)

- **Structured module logs**: `logs/mod*/mod*-<action>-<session>.json`
- **Reports/artifacts**: `report/`
  - `report/FINAL_REPORT_TEMPLATE.md`
  - `report/detection_matrix.{md,json}` (generated by Module 7 helper)
  - `report/multichain_story.{md,json}` (generated by Workbench multi-chain)
  - `report/multichain_casefile.json` (same casefile JSON; easier to import elsewhere)
  - `report/suricata/` and `report/zeek/` (offline IDS outputs, if used)
- **NetVis persistence database**: `data/netvis.db`
  - tables: `assets`, `services`, `flows`, `dns_queries`, `alerts`, `observations`, `scan_jobs`, `coursework_jobs`

## UI Capability Sheet (Everything You Can Click)

The header has a view toggle:
- `Graph`
- `Dashboard`
- `Workbench`
- `NIP`
- `Coursework`

### Graph View (Interactive Topology + Device Details)

Primary intent: discover hosts, visualize connections, drill into devices.

What it does:
- Starts a background **scan job** (`quick|standard|deep`) and updates discovered devices.
- Shows a force-directed graph of devices (nodes) and observed traffic (edges).
- Clicking a device opens the **Device Panel** (ports/services/banners if available).
- Supports **Start Capture / Stop Capture** (live sniffing) to populate flows, DNS, and alerts.

Backend calls (high level):
- `POST /api/scan/jobs` and `GET /api/scan/jobs/<job_id>`
- `GET /api/devices`, `GET /api/connections`, `GET /api/stats`, `GET /api/dns`, `GET /api/alerts`
- `POST /api/device/<ip>/scan` (per-device deep port scan)
- `POST /api/capture/start`, `POST /api/capture/stop`

### Dashboard View (Metrics + Correlated Intel)

Primary intent: summarize what capture/scans have learned.

Panels:
- Traffic totals + internal/external split
- Protocol + application breakdown
- Top talkers
- DNS query trends
- Alerts panel
- Intel story panel (high-level narrative from persisted evidence)

### Workbench View (Multi-Chain Discovery + Story Synthesis)

Primary intent: run a staged recon chain and output a **casefile** + **narrative story**.

UI actions:
- Configure: profile, network CIDR, interface, host limits, ports, durations, optional DNS domain, lab-only fields.
- Click **Run Multi-Chain**.
- Click **Load Latest Story** to render the aggregated view.
- Click **Open Story.md** or **Open Casefile** to view full artifacts.

Artifacts written:
- `report/multichain_story.json`
- `report/multichain_story.md`
- `report/multichain_casefile.json`

### Coursework View (Rubric Runner + Logs + IDS Helpers)

Primary intent: run each rubric technique with one click, keep evidence organized, and open logs/artifacts from the UI.

UI actions:
- Per-module “Run” buttons for each rubric item (Modules 1–7).
- Additional “Run” buttons for expanded NIP modules:
  - `ipv6`, `dhcp`, `discovery`, `icmp`, `tls`, `dns`, `snmp`, `ssh`, `smb`, `iot`, `wifi`, `vlan`, `analysis`, `threat`
- Background job tracking and progress.
- Log browser (per module) with JSON viewer.
- Artifact viewer for `report/*` outputs.
- Convenience to generate a PCAP from promisc capture and reuse it for offline Suricata/Zeek.

### NIP View (Roadmap Substrate Console)

Primary intent: inspect the “Palantir-style” substrate (registry, event bus, baselines) that makes multi-source fusion possible.

What it does:
- Shows **technique registry** from `GET /api/nip/techniques`.
- Shows recent **event bus** events from `GET /api/nip/events`.
- Controls the **metrics/baselining daemon**:
  - `GET /api/nip/daemon/status`
  - `POST /api/nip/daemon/start`
  - `POST /api/nip/daemon/stop`
- Views recent **metrics** + **baselines**:
  - `GET /api/nip/metrics?ip=<IP>`
  - `GET /api/nip/baselines?ip=<IP>`
- Runs an optional **local threat indicator check** (no downloads):
  - `GET /api/nip/threat/check`
  - indicator file: `samples/threat_indicators.json` (or set `NIP_THREAT_FEED_PATH`)

## Multi-Chain Discovery (Workbench) - What Runs, In What Order

The Workbench uses the backend pipeline:
- module: `pipeline`
- action: `multichain`
- implementation: `server.py::run_multichain_pipeline()`

### Inputs (Workbench Config -> Pipeline Params)

Core:
- `profile`: `quick | standard | deep`
- `network`: CIDR to sweep (default from backend status)
- `interface`: capture/ARP interface
- `maxHosts`: cap discovered hosts used by later stages

Transport:
- `tcpPorts`: CSV (default `22,80,443`)
- `udpPorts`: CSV (default `53,123,161`)

Application:
- `bannerPorts`: CSV (default `21,22,25,80,443`)
- `domain` + `dnsServer` (optional active DNS enum)

IP-layer:
- `dport` (default 80)
- `fragsize`, `overlap`
- `ttlMethod` + `maxHops`

Lab-only:
- `labOk` (must be checked to enable spoofing steps in deep)
- `zombieIp` (idle scan)
- `decoys` (decoy mixing)

### Derived Targets (How the Pipeline Chooses What To Probe)

- `discovered_ips`: taken from Module 1 active ARP replies (minus scanner IP and gateway IP), truncated to `maxHosts`.
- `primary_target`: `targetIp` if provided, else the first discovered host.
- `fingerprint_hosts`: discovered hosts ranked by “open TCP ports found by SYN scan”, capped by profile:
  - quick: 6 hosts
  - standard: 12 hosts
  - deep: 20 hosts

### Profile: quick

1. **Module 1 (1a)** Active ARP Enumeration
2. **Module 2 (2a)** TCP SYN scan across `discovered_ips` × `tcpPorts`
3. **Module 5 (5a/5c/5b)** Banner grabbing for `fingerprint_hosts`; plus HTTP/TLS where open
4. **Module 5 (5d)** TCP stack fingerprinting on `primary_target`
5. **Module 3 (3b/3a)** TTL path inference + IP fragmentation on `primary_target`
6. **Synthesis** casefile + narrative story

### Profile: standard

Everything in `quick`, plus:

1. **Module 1 (1b)** Passive ARP Observation (duration=`durationShort`)
2. **Module 2 (2f)** UDP scan (first ~16 hosts)
3. **Module 2 (2g)** ACK scan (first ~8 hosts) for firewall inference
4. **Module 5 (5e)** Passive DNS monitor (duration=`durationShort`)
5. **Module 7 (7c)** ARPwatch-style monitor (duration=`durationArpwatch`)
6. **Module 6 (6a)** Promiscuous capture (duration=`durationShort`, optional `bpf`)
7. **Synthesis**

### Profile: deep

Everything in `standard`, plus:

1. **Module 1 (1c)** MAC randomization ARP session
2. **Module 2 (2c/2d/2e)** FIN / XMAS / NULL scans on `primary_target`
3. **Module 3 (3c)** IPID sweep (find suitable zombies faster)
4. **Module 3 (3c/3d, lab-only)** Idle scan and/or decoy mixing if `labOk` is checked and inputs are provided
5. **Module 6 (6c)** NetFlow v5 collection (if exporter present)
6. **Module 7 (7c)** NetFlow detection alerting (timestamped)
7. **Module 7 helper** Detection matrix correlation (only if you provide Suricata/Zeek log paths in config)
8. **Synthesis**

### Synthesis Output (What “The Story” Contains)

The generated casefile JSON (also used by the Workbench UI) includes:
- `summary`: counts (hosts, ports, exposures, etc.)
- `assets`: normalized asset list with vendor + open ports + risk ports
- `exposures`: “high risk service” findings (SMB/RDP/FTP/Telnet/etc.)
- `web_findings`: HTTP posture + “caching layer detected” hints + internal IP leak checks
- `tls_highlights`: leaf certificate subject/issuer/SANs/validity/key size/signature
- `host_profiles`: per-host “fused profile”
  - services + banners + extracted intel
  - firewall inference (ACK scan)
  - UDP observations
  - OS hints (heuristics + tcpfp on primary)
- `steps`: full step list with module/action/params/log paths
- `evidence_logs`: every `logs/mod*/...json` path produced by the run

Artifacts:
- `report/multichain_story.json` (the complete casefile)
- `report/multichain_casefile.json` (same JSON; stable filename)
- `report/multichain_story.md` (human-readable narrative + inventory tables)

## “Chained Discovery” Command Chain (CLI Equivalent)

The Workbench multi-chain is the recommended path (it automates target selection + synthesis), but you can reproduce it manually.

### Variables

```bash
NETWORK="192.168.56.0/24"
IFACE="en0"
MAX_HOSTS="32"
TCP_PORTS="22,80,443"
UDP_PORTS="53,123,161"
BANNER_PORTS="21,22,25,80,443"
PRIMARY_TARGET="192.168.56.10"  # optional; otherwise pick one from mod1 output
DOMAIN="example.com"            # optional
DNS_SERVER="8.8.8.8"
```

### Step 1: Active ARP (discover hosts)

```bash
sudo venv/bin/python mod1/link_layer_discovery.py active --network "$NETWORK" --interface "$IFACE" --max-hosts "$MAX_HOSTS"
```

This writes a log under `logs/mod1/`. Extract discovered IPs:

```bash
python - <<'PY'
import glob, json
path = sorted(glob.glob("logs/mod1/mod1-active-*.json"))[-1]
obj = json.load(open(path))
hosts = [h["ip"] for h in obj.get("hosts", []) if isinstance(h, dict) and h.get("ip")]
print("\n".join(hosts))
PY
```

### Step 2: SYN scan (baseline ports + host ranking)

```bash
sudo venv/bin/python mod2/transport_scans.py --network "$NETWORK" --ports "$TCP_PORTS" --shuffle syn
```

### Step 3: App fingerprinting

Banner grab on the primary target (or repeat per host you care about):

```bash
sudo venv/bin/python mod5/app_fingerprinting.py banner --host "$PRIMARY_TARGET" --ports "$BANNER_PORTS"
```

HTTP headers:

```bash
venv/bin/python mod5/app_fingerprinting.py http --host "$PRIMARY_TARGET" --port 80
venv/bin/python mod5/app_fingerprinting.py http --host "$PRIMARY_TARGET" --port 443 --tls
```

TLS chain:

```bash
venv/bin/python mod5/app_fingerprinting.py tls --host "$PRIMARY_TARGET" --port 443
```

TCP stack fingerprint:

```bash
sudo venv/bin/python mod5/app_fingerprinting.py tcpfp --host "$PRIMARY_TARGET" --dport 80
```

Optional DNS enumeration:

```bash
venv/bin/python mod5/app_fingerprinting.py dns --domain "$DOMAIN" --server "$DNS_SERVER"
```

Optional passive DNS (local network only):

```bash
sudo venv/bin/python mod5/app_fingerprinting.py passive-dns --interface "$IFACE" --duration 60
```

### Step 4: IP-layer techniques on primary target

TTL path inference:

```bash
sudo venv/bin/python mod3/ip_layer_techniques.py ttl --target "$PRIMARY_TARGET" --max-hops 20 --method icmp --dport 80
```

Fragmentation test:

```bash
sudo venv/bin/python mod3/ip_layer_techniques.py frag --target "$PRIMARY_TARGET" --dport 80 --fragsize 8 --overlap
```

### Step 5: Standard/Deep extras

Passive ARP:

```bash
sudo venv/bin/python mod1/link_layer_discovery.py passive --duration 60 --interface "$IFACE"
```

UDP scan + ACK scan:

```bash
sudo venv/bin/python mod2/transport_scans.py --network "$NETWORK" --ports "$UDP_PORTS" --shuffle udp
sudo venv/bin/python mod2/transport_scans.py --network "$NETWORK" --ports "$TCP_PORTS" --shuffle ack
```

ARPwatch-style monitoring:

```bash
sudo venv/bin/python mod7/arpwatch_like.py --interface "$IFACE" --duration 120
```

Promisc capture (and write a PCAP for offline IDS):

```bash
sudo venv/bin/python mod6/passive_collection.py promisc --interface "$IFACE" --duration 60 --pcap-out report/capture.pcap
```

Offline Suricata/Zeek against that PCAP (if installed):

```bash
venv/bin/python mod7/ids_offline.py suricata --pcap report/capture.pcap --timeout 120
venv/bin/python mod7/ids_offline.py zeek --pcap report/capture.pcap --timeout 120
```

Detection matrix correlation (uses stable defaults written by offline runs):

```bash
venv/bin/python mod7/detection_matrix.py --suricata-eve report/suricata/eve.json --zeek-notice report/zeek/notice.log
```

### Step 6: Module 4 timing experiments (rubric completeness)

```bash
sudo venv/bin/python mod4/timing_rate_control.py fixed --host "$PRIMARY_TARGET" --ports "$TCP_PORTS" --max-tuples 10
sudo venv/bin/python mod4/timing_rate_control.py jitter --host "$PRIMARY_TARGET" --ports "$TCP_PORTS" --base-delay 0.4 --max-tuples 30
sudo venv/bin/python mod4/timing_rate_control.py order --host "$PRIMARY_TARGET" --ports "$TCP_PORTS" --delay 0.4 --max-tuples 30
```

### Step 7: Deep-only (lab_ok) spoofing exercises

IPID sweep:

```bash
sudo venv/bin/python mod3/ip_layer_techniques.py ipid-sweep --network "$NETWORK" --max-hosts 64 --probes 12
```

Idle scan (lab only):

```bash
sudo venv/bin/python mod3/ip_layer_techniques.py idle --lab-ok --zombie <ZOMBIE_IP> --target "$PRIMARY_TARGET" --dport 22
```

Decoy mixing (lab only):

```bash
sudo venv/bin/python mod3/ip_layer_techniques.py decoy --lab-ok --target "$PRIMARY_TARGET" --dport 80 --decoy <DECOY_1> --decoy <DECOY_2>
```

## Multi-Chain via API (Optional)

If you want a “command chain” that uses the same path as the UI (job queue + artifacts), you can do it with `curl`.

Start a multi-chain job:

```bash
curl -sS -X POST http://127.0.0.1:5001/api/coursework/jobs \\
  -H 'Content-Type: application/json' \\
  -d '{
    "module":"pipeline",
    "action":"multichain",
    "params":{
      "profile":"standard",
      "network":"192.168.56.0/24",
      "interface":"en0",
      "maxHosts":32,
      "tcpPorts":"22,80,443",
      "udpPorts":"53,123,161",
      "bannerPorts":"21,22,25,80,443"
    }
  }'
```

List jobs:

```bash
curl -sS 'http://127.0.0.1:5001/api/coursework/jobs?limit=10'
```

Fetch the story artifact:

```bash
curl -sS 'http://127.0.0.1:5001/api/coursework/report/multichain_story.json'
```

## Notes For Maximizing Rubric Points

- Use the **Coursework** tab to run each rubric technique directly; the UI shows the exact CLI command that corresponds to the job.
- Use **Module 4** with `--max-tuples` so the “1 probe / 5 minutes” profile is still feasible.
- Generate at least one **PCAP** (`mod6 promisc --pcap-out report/capture.pcap`) and run offline **Suricata + Zeek**, then use the **detection matrix** to produce a clean “what fired per technique” report.
- Use `report/FINAL_REPORT_TEMPLATE.md` as your final deliverable skeleton, and cite:
  - the exact command,
  - the `logs/mod*/...json` file,
  - any `report/*` artifacts used (pcaps, IDS outputs, detection matrix, multichain story).
